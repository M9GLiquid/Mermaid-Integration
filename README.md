# Integration-v1

Minimal integration package that connects three APIs for hand recognition with grid layout management.

## Architecture (Separation of Concerns)

This integration follows SoC principles with three independent APIs:

1. **Hand Recognition API** (`hand_recognition/`)
   - Detects hand gestures (Open_Palm, Closed_Fist)
   - Provides hand position coordinates from camera stream
   - Uses MediaPipe for gesture recognition

2. **Overlay API** (`overlay/overlay-api.py`)
   - Transforms coordinates: GPS server â†’ Rectified â†’ Grid cells
   - Handles perspective correction and grid overlay
   - Provides coordinate transformation functions

3. **Layout API** (`object-layout/api/layout-api.py`)
   - Manages grid map (walls, home positions, obstacles)
   - Provides colored symbol display
   - Handles grid persistence and access

## Structure

```
Integration-v1/
â”œâ”€â”€ main.py                    # Main orchestrator (connects all APIs)
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ hand_grid_demo.py     # Demo implementation
â”œâ”€â”€ hand_recognition/
â”‚   â”œâ”€â”€ hand_recognition.py   # Hand recognition module
â”‚   â””â”€â”€ gesture_recognizer.task  # MediaPipe model
â”œâ”€â”€ overlay/
â”‚   â”œâ”€â”€ overlay-api.py        # GPSOverlay API
â”‚   â””â”€â”€ gps_overlay.json      # Calibration data
â””â”€â”€ object-layout/
    â””â”€â”€ api/
        â”œâ”€â”€ layout-api.py     # Layout API (standalone)
        â””â”€â”€ grid.json          # Grid data
```

## Usage

Run the integration:

```bash
python3 main.py
```

The integration will:
1. Initialize all three APIs
2. Start hand recognition from camera stream
3. Transform hand coordinates to grid cells
4. Update grid based on gestures (in memory only)
5. Display grid with colored symbols in terminal

## Testing

Test the APIs individually:

```bash
# Test Layout API
python3 test_layout_api.py

# Test Overlay API
python3 test_overlay_api.py

# Test specific overlay functionality
python3 test_overlay_api.py test_coordinates
python3 test_overlay_api.py test_grid_cells
python3 test_overlay_api.py test_stream_transform
```

## Gestures

- **Open_Palm (FOOD)** â†’ Marks cell as HOME (ğŸ)
- **Closed_Fist (THREAT)** â†’ Marks cell as OBSTACLE (âš ï¸)

## Requirements

- Python 3.8+
- `mediapipe` - Hand gesture recognition
- `opencv-python` - Camera stream handling
- `numpy` - Numerical operations

## Standalone

This package is completely standalone:
- All APIs are self-contained
- No dependencies on other Mermaid projects
- Can be copied and used independently
- Each module can be replaced without affecting others

## API Independence

Each API is independent and can be replaced:
- **Hand Recognition**: Replace `hand_recognition.py` with different recognition system
- **Overlay**: Replace `overlay-api.py` with different coordinate transformation
- **Layout**: Replace `layout-api.py` with different grid management

The `main.py` orchestrator connects them together following SoC principles.
